{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MS2_face_det.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "91eHCma8UEyu"
      },
      "source": [
        "# **MileStone 2**\n",
        "---\n",
        "This document contains the first part of our model, which intends to **preprocess received images (of people)** into a format that can be applied for the GAN. This part concentrates on detecting faces on images, cropping them and exporting the results into a different folder.\n",
        "\n",
        "Basic exception handling is implemented as well (though its not perfect yet).\n",
        "\n",
        "**The second part of our model can be found [here](https://colab.research.google.com/drive/1ee8G2lxnjfxIth1dT9mu7wT-IHC6ULo6?usp=sharing)**. We decided to separate them as we've been working on these independently. However we are planning to collect all the source codes into one, single notebook after we finish the project.\n",
        "\n",
        "\n",
        "**Source**: *the source webpage, which I've used to create this can be found [here](https://realpython.com/face-recognition-with-python/). The source for the pretrained set's xml and the way of detecting faces can be found here too.*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0S-cZNUQXR2c",
        "outputId": "e4ca4c18-3f6d-4256-cebf-c36497d99209"
      },
      "source": [
        "from google.colab import drive\n",
        "import os\n",
        "drive.mount(\"/content/drive\")\n",
        "import cv2\n",
        "import re\n",
        "from IPython.display import clear_output\n",
        "\n",
        "#more convinient workplace\n",
        "%cd drive/MyDrive/deeplearning/resource "
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n",
            "/content/drive/MyDrive/deeplearning/resource\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3QUM_2WnUBti"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "Here we're unzipping the input images that show regular people. We've realized that these images are not all the best match for this task, so we are going to need to clean them later on. As written in the readme.md, we're using a pretrained model here, so we wont need to train it. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FNQHhnEeOVtE",
        "outputId": "9061512a-a953-40dc-bf3e-9d483fbb3272"
      },
      "source": [
        "#Load the cascade\n",
        "face_cascade = cv2.CascadeClassifier('face_detector.xml')\n",
        "\n",
        "#%cd resource\n",
        "!unzip face_detection.zip -d input\n",
        "clear_output(wait=True)\n",
        "print('images unzipped')\n",
        "\n",
        "# Load the images\n",
        "images = [f for f in os.listdir('input/test')  if f.endswith(\".jpg\")]\n",
        "print(\"Number of input files: {}\".format(len(images)))"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "images unzipped\n",
            "Number of input files: 200\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bJfMeqStqhWl"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "The last part of our task here is to crop and resize the images, so that they can be fed to the GAN in the second model. It yet needs to be finetuned, and the cropping is not properly set either (and I am also kind of annoyed due to the filehandling we're commiting here), but we expect this code to serve as a proper baseline.\n",
        "\n",
        "The names of the images that could not be processed (no faces found, or othe kind of errors) are collected into a single .txt file called **invalid_images.txt** . \n",
        "\n",
        "**results of this model can be seen in the gan_input_images folder**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xAOzUBr2Xf-0"
      },
      "source": [
        "def crop_and_resize_image(face, img, dim):\n",
        "  x, y, w, h = face\n",
        "  crop_img = img[y:y+h, x:x+w] # Todo finetune this part\n",
        "  resized = cv2.resize(crop_img, dim, interpolation = cv2.INTER_AREA)\n",
        "  return resized"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5U-OvX37Ye9E"
      },
      "source": [
        "width = 256\n",
        "height = 256\n",
        "def process_image(image_name):\n",
        "    try:\n",
        "      img = cv2.imread(\"input/test/\" + image_name)\n",
        "      faces = face_cascade.detectMultiScale(img, 1.1, 2) # TODO find the best parameters\n",
        "      if len(faces) >= 1:\n",
        "        resized = crop_and_resize_image(faces[0], img, (width, height))\n",
        " \n",
        "        cv2.imwrite(\"/content/drive/MyDrive/deeplearning/resource/gan_input_images/cropped_\" + image_name, resized)     \n",
        "        clear_output(wait=True)\n",
        "        print(image_name + \" cropped\")\n",
        "\n",
        "    except:\n",
        "      f = open(\"invalid_images.txt\", \"a+\")\n",
        "      f.write(image_name + \"\\n\")\n",
        "      f.close()\n",
        "\n",
        "    clear_output(wait=True)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nbHn24C2cwUA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "77bf861f-c9d6-47f8-e061-6e6bea1d0156"
      },
      "source": [
        "for image in images:\n",
        "    process_image(image)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "9_Press_Conference_Press_Conference_9_756.jpg cropped\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}